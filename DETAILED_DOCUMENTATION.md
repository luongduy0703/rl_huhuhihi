# Robot Arm Controller - Detailed Technical Documentation

## üîß Hardware Controller Analysis

### PCA9685 PWM Controller Overview
The PCA9685 is a 16-channel PWM (Pulse Width Modulation) controller that communicates with the Raspberry Pi via I2C protocol.

### Key Parameters Explained

#### Pulse Width Parameters
```python
min_pulse: int = 500    # Minimum pulse width (microseconds)
max_pulse: int = 2500   # Maximum pulse width (microseconds)
```

**What these mean:**
- **min_pulse (500Œºs)**: Pulse width that corresponds to 0¬∞ servo position
- **max_pulse (2500Œºs)**: Pulse width that corresponds to 180¬∞ servo position
- **Standard servo control**: Most hobby servos expect 1000-2000Œºs, but 500-2500Œºs gives better range

#### How Pulse Width Controls Servos:
1. **PWM Signal**: 50Hz frequency (20ms period)
2. **Pulse Width**: Duration of HIGH signal within each 20ms period
3. **Servo Response**: Internal servo controller converts pulse width to position

```
Servo Angle Calculation:
angle_in_degrees = (pulse_width - min_pulse) / (max_pulse - min_pulse) * 180

Example:
- 500Œºs  ‚Üí 0¬∞
- 1500Œºs ‚Üí 90¬∞ (neutral)
- 2500Œºs ‚Üí 180¬∞
```

### Complete Processing Flow

#### 1. Initialization Process
```python
def __init__(self, num_servos=4, min_pulse=500, max_pulse=2500):
```

**Step-by-step initialization:**
1. **Hardware Detection**: Check if CircuitPython libraries available
2. **I2C Setup**: Initialize I2C bus (SCL/SDA pins)
3. **PCA9685 Config**: Set 50Hz frequency for servo control
4. **Position Tracking**: Initialize current_positions array
5. **Safety Limits**: Set angle limits (0-180¬∞) for each servo
6. **Neutral Position**: Move all servos to 90¬∞ starting position

#### 2. Angle-to-Pulse Conversion
```python
def angle_to_pulse(self, angle: float) -> int:
    pulse = self.min_pulse + (angle / 180.0) * (self.max_pulse - self.min_pulse)
    return int(pulse)
```

**Mathematical Process:**
- Input: Angle (0-180 degrees)
- Linear interpolation between min_pulse and max_pulse
- Output: Pulse width in microseconds

**Example Calculations:**
- 0¬∞   ‚Üí 500 + (0/180) √ó (2500-500) = 500Œºs
- 90¬∞  ‚Üí 500 + (90/180) √ó (2500-500) = 1500Œºs  
- 180¬∞ ‚Üí 500 + (180/180) √ó (2500-500) = 2500Œºs

#### 3. Servo Control Process
```python
def set_servo_angle(self, servo_id: int, angle: float) -> bool:
```

**Processing Steps:**
1. **Validation**: Check servo_id (0-15) and angle limits
2. **Clamping**: Ensure angle within servo limits
3. **Conversion**: angle ‚Üí pulse width ‚Üí 16-bit duty cycle
4. **Hardware Write**: Send PWM signal to PCA9685 channel
5. **State Update**: Update current_positions tracking
6. **Error Handling**: Return success/failure status

**16-bit Duty Cycle Calculation:**
```python
duty_cycle = int(pulse * 65535 / 20000)
```
- 65535: Maximum 16-bit value
- 20000: 20ms period in microseconds
- Result: Proportion of HIGH time in PWM signal

### Input/Output Specifications

#### Inputs
1. **Servo ID**: Integer (0-15, typically 0-3 for 4-joint arm)
2. **Target Angle**: Float (0.0-180.0 degrees)
3. **Movement Parameters**: Steps, delay for smooth motion
4. **Safety Limits**: Min/max angles for each joint

#### Outputs
1. **PWM Signals**: 50Hz PWM to servo motors
2. **Position Feedback**: Current joint angles array
3. **Status Codes**: Success/failure boolean returns
4. **Debug Information**: Console output for monitoring

#### Hardware Connections
```
Raspberry Pi 4 ‚Üí PCA9685 ‚Üí Servos
GPIO 2 (SDA) ‚îÄ‚îÄ‚îê
GPIO 3 (SCL) ‚îÄ‚îÄ‚î§ I2C Bus ‚Üí PCA9685 Board
5V Power   ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
Ground     ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

PCA9685 Channels:
Channel 0 ‚Üí Base Servo (Joint 1)
Channel 1 ‚Üí Shoulder Servo (Joint 2)  
Channel 2 ‚Üí Elbow Servo (Joint 3)
Channel 3 ‚Üí Wrist Servo (Joint 4)
```

### Safety Features

#### 1. Angle Limits
```python
self.angle_limits = [(0, 180) for _ in range(self.num_servos)]
```
- Prevents servo damage from over-rotation
- Customizable per joint
- Hardware protection

#### 2. Input Validation
- Servo ID range checking
- Angle clamping to valid ranges
- Exception handling for hardware errors

#### 3. Smooth Movement
```python
def move_servo_smoothly(self, servo_id, target_angle, steps=20, delay=0.05):
```
- Prevents sudden jerky movements
- Reduces mechanical stress
- Configurable speed control

### Performance Characteristics

#### Timing Specifications
- **PWM Frequency**: 50Hz (20ms period)
- **Update Rate**: ~50 updates/second maximum
- **Smooth Movement**: Configurable (default: 20 steps, 0.05s delay)
- **I2C Speed**: Standard 100kHz

#### Precision
- **Angle Resolution**: ~0.35¬∞ (500 steps over 180¬∞)
- **Pulse Resolution**: ~4Œºs (2000Œºs range / 500 steps)
- **Repeatability**: ¬±1¬∞ typical for hobby servos

### Error Handling

#### Common Error Scenarios
1. **Hardware Not Connected**: Falls back to simulation mode
2. **Invalid Servo ID**: Returns False, logs error
3. **I2C Communication Error**: Exception catching, retry logic
4. **Angle Out of Range**: Automatic clamping to limits

#### Debug Output Examples
```
PCA9685 initialized successfully
Hardware libraries not available - running in simulation mode
Error setting servo 2 to angle 200: Angle clamped to 180
Invalid servo ID: 8
```

---

## üß† Reinforcement Learning Environment

### Environment State Representation
The robot arm environment provides state information to the RL agent:

#### State Vector (10 elements):
1. **Joint Angles (4)**: Normalized current positions [-1, 1]
2. **Target Position (3)**: 3D coordinates of target [x, y, z]
3. **End Effector Position (3)**: Current arm tip position [x, y, z]

#### State Processing:
```python
def _get_observation(self):
    # Normalize joint angles to [-1, 1]
    normalized_angles = 2 * (current_angles - min_angle) / (max_angle - min_angle) - 1
    
    # Get end effector position via forward kinematics
    end_pos = self._forward_kinematics(self.current_joint_angles)
    
    # Combine into state vector
    state = [normalized_angles, target_position, end_pos]
    return state
```

### Action Space
The RL agent outputs actions that control servo movements:

#### Continuous Actions (DDPG):
- **Range**: [-1, 1] for each joint
- **Conversion**: action ‚Üí angle via linear scaling
- **Example**: action=0.5 ‚Üí 135¬∞ (3/4 of range from 0-180¬∞)

#### Discrete Actions (DQN):
- **Action Set**: {-10¬∞, -5¬∞, 0¬∞, +5¬∞, +10¬∞} per joint
- **Combination**: 5^4 = 625 possible actions
- **Selection**: Agent chooses single action index

### Reward Function Design
The reward system teaches the robot to reach targets efficiently:

#### Components:
```python
def _calculate_reward(self):
    # 1. Distance improvement reward
    current_distance = ||end_position - target_position||
    distance_reward = previous_distance - current_distance
    
    # 2. Target reached bonus
    target_bonus = 10.0 if current_distance < 0.05 else 0.0
    
    # 3. Movement penalty (smooth motion)
    movement_penalty = -0.01 * sum(|angle_changes|)
    
    # 4. Total reward
    total_reward = distance_reward + target_bonus + movement_penalty
    return total_reward
```

#### Reward Ranges:
- **Distance improvement**: -‚àû to +‚àû (typically -0.5 to +0.5)
- **Target bonus**: 0 or +10.0
- **Movement penalty**: -0.01 to -0.5
- **Total range**: -‚àû to +10.0 (typically -2.0 to +10.0)

---

## üîÑ Complete Processing Pipeline

### Training Loop (Simplified Version)

```python
# 1. Environment Reset
state = env.reset()  # Returns initial state vector (10 elements)

for step in range(max_steps):
    # 2. Agent Action Selection
    action = agent.act(state)  # Returns action vector (4 elements)
    
    # 3. Environment Step
    next_state, reward, done, info = env.step(action)
    
    # 4. Experience Storage
    agent.remember(state, action, reward, next_state, done)
    
    # 5. Learning Update
    if len(agent.memory) > batch_size:
        agent.replay()  # Train neural networks
    
    # 6. State Update
    state = next_state
    
    if done:
        break
```

### Hardware Integration Pipeline

```python
# 1. RL Agent Decision
action = agent.act(current_state)  # [-1, 1] range

# 2. Action Scaling
servo_angles = []
for i, action_val in enumerate(action):
    min_angle, max_angle = joint_limits[i]
    angle = min_angle + (action_val + 1) * (max_angle - min_angle) / 2
    servo_angles.append(angle)

# 3. Hardware Control
controller.set_all_servos(servo_angles)

# 4. State Feedback
new_positions = controller.get_current_positions()
end_position = forward_kinematics(new_positions)
new_state = create_state_vector(new_positions, target, end_position)

# 5. Reward Calculation
reward = calculate_reward(end_position, target)

# 6. Next Iteration
current_state = new_state
```

This detailed breakdown shows how the entire system processes information from high-level RL decisions down to low-level PWM signals controlling physical servos, with feedback loops ensuring the robot learns to accomplish its tasks effectively.
